{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv('Data1.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into train and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset into Training and Test groups (use 20-80 split)\n",
    "from sklearn.model_selection import train_test_split\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, -1].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# feature scaling\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc_X = StandardScaler()\n",
    "X_train = sc_X.fit_transform(X_train)\n",
    "X_test = sc_X.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare reusable functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(model):\n",
    "    y_pred = model.predict(X_test)\n",
    "    print(np.concatenate((y_pred.reshape(len(y_pred),1), y_test.reshape(len(y_test),1)),1))\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metrics(y_test, y_pred):\n",
    "    from sklearn.metrics import confusion_matrix, accuracy_score, classification_report\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    print(cm)\n",
    "    print(\"Accuracy score = {}\".format(accuracy_score(y_test, y_pred)))\n",
    "    \n",
    "    print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "def k_fold(model, X, y, k):\n",
    "    accuracies = cross_val_score(estimator=model, X=X_train, y=y_train, cv=k)\n",
    "    print(\"accuracies = {}\".format(accuracies))\n",
    "    print(\"max accuracy = {}\".format(accuracies.max()))\n",
    "    print(\"mean = {}\".format(accuracies.mean() * 100))\n",
    "    print(\"std = {}\".format(accuracies.std() * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(random_state=0)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "lreg_classifier = LogisticRegression(random_state = 0)\n",
    "lreg_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 4]\n",
      " [4 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]]\n"
     ]
    }
   ],
   "source": [
    "lreg_predictions = predict(lreg_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[84  3]\n",
      " [ 3 47]]\n",
      "Accuracy score = 0.9562043795620438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.97      0.97      0.97        87\n",
      "           4       0.94      0.94      0.94        50\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics(y_test, lreg_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are 84 cases when the class was the class was 2 and is was correctly predicted\n",
    "* There are 3 cases when the class was 2 and is was incorrectly predicted\n",
    "* There are 3 cases when the class was 4 and it was incorrectly predicted\n",
    "* There are 47 cases when the class was 4 and is was correctly predicted\n",
    "\n",
    "The accuracy is almost 0.96. I may be overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies = [0.94545455 0.96363636 0.96363636 1.         0.94545455 1.\n",
      " 0.96296296 0.96296296 0.98148148 0.94444444]\n",
      "max accuracy = 1.0\n",
      "mean = 96.70033670033669\n",
      "std = 1.9697976894447813\n"
     ]
    }
   ],
   "source": [
    "k_fold(lreg_classifier, X_train, y_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard variation is low meaning that we can consider the mean accuracy as a good one. But the accuracies are highin some cases they are even 100%. This adaset is too small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', random_state=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision tree classifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "dtree_classifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\n",
    "dtree_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]]\n"
     ]
    }
   ],
   "source": [
    "dtree_perdictions = predict(dtree_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[85  2]\n",
      " [ 2 48]]\n",
      "Accuracy score = 0.9708029197080292\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.98      0.98      0.98        87\n",
      "           4       0.96      0.96      0.96        50\n",
      "\n",
      "    accuracy                           0.97       137\n",
      "   macro avg       0.97      0.97      0.97       137\n",
      "weighted avg       0.97      0.97      0.97       137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics(y_test, dtree_perdictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are 85 cases when the class was 2 and is was correctly predicted\n",
    "* There are 2 cases when the class was 2 and is was incorrectly predicted\n",
    "* There are 2 cases when the class was 4 and it was incorrectly predicted\n",
    "* There are 48 cases when the class was 4 and it was correclty predicted\n",
    "\n",
    "The accuracy score is bigger than the logistic regression accuracy. This accuracy is quite big."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies = [0.96363636 0.92727273 0.96363636 0.94545455 0.96363636 0.92727273\n",
      " 0.90740741 0.96296296 1.         0.96296296]\n",
      "max accuracy = 1.0\n",
      "mean = 95.24242424242425\n",
      "std = 2.4905835653388118\n"
     ]
    }
   ],
   "source": [
    "k_fold(dtree_classifier, X_train, y_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With desicion tree classifier we've got a lower mean accuracy but a higher standard deviation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(n_estimators=10, random_state=0)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest Classifier (with nb_trees = 10)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc_classifier = RandomForestClassifier(n_estimators = 10, random_state = 0)\n",
    "rfc_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]]\n"
     ]
    }
   ],
   "source": [
    "rfc_predictions = predict(rfc_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[84  3]\n",
      " [ 3 47]]\n",
      "Accuracy score = 0.9562043795620438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.97      0.97      0.97        87\n",
      "           4       0.94      0.94      0.94        50\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.95      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics(y_test, rfc_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisengly the accuracy of the random forest classifier is same as the logistic regression accuracy and the consuption of the memory is also same as the logistic regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies = [0.94545455 0.96363636 0.94545455 1.         0.94545455 1.\n",
      " 0.94444444 0.96296296 1.         0.94444444]\n",
      "max accuracy = 1.0\n",
      "mean = 96.51851851851852\n",
      "std = 2.381554575703594\n"
     ]
    }
   ],
   "source": [
    "k_fold(rfc_classifier, X_train, y_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For k-fold cross validation we've got same results as in the case of logistic regression."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Nearest Neighbors (K-NN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# K- Nearest Neighbors (K-NN)\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "knn_classifier = KNeighborsClassifier()\n",
    "knn_classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]]\n"
     ]
    }
   ],
   "source": [
    "knn_predictions = predict(knn_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83  4]\n",
      " [ 2 48]]\n",
      "Accuracy score = 0.9562043795620438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.98      0.95      0.97        87\n",
      "           4       0.92      0.96      0.94        50\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.96      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics(y_test, knn_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There are 83 cases when the class was 2 and it was correclty predicted\n",
    "* There are 4 cases when the class was 2 and it was incorrectly predicted\n",
    "* There are 2 cases when the class was 4 and it was incorrectly predicted\n",
    "* There are 48 cases when the class was 4 and it was correctly predicted\n",
    "\n",
    "The accuracy is almost the same as the accurancy given by the random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies = [0.94545455 0.94545455 0.98181818 0.98181818 0.96363636 1.\n",
      " 0.96296296 0.96296296 0.98148148 0.94444444]\n",
      "max accuracy = 1.0\n",
      "mean = 96.70033670033669\n",
      "std = 1.7941421104663395\n"
     ]
    }
   ],
   "source": [
    "k_fold(knn_classifier, X_train, y_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The accuracies are very simmilar to the ones obtained above. There is not much difference between all these classifiers in the way how they predict by using this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naïve Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB()"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naïve Bayes\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]]\n"
     ]
    }
   ],
   "source": [
    "naive_predictions = predict(nb_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[80  7]\n",
      " [ 0 50]]\n",
      "Accuracy score = 0.948905109489051\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       1.00      0.92      0.96        87\n",
      "           4       0.88      1.00      0.93        50\n",
      "\n",
      "    accuracy                           0.95       137\n",
      "   macro avg       0.94      0.96      0.95       137\n",
      "weighted avg       0.96      0.95      0.95       137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics(y_test, naive_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this model we've got a bit different result for the confusion matrix and a lower accuracy in comparison to the other classifiers.\n",
    "\n",
    "* There are 80 cases when the class was 2 and it was correctly predicted\n",
    "* There are 7 cases when the class was 2 and it was incorrectly predicted\n",
    "* There are 0 cases when the class was 4 and it was incorrectly predicted\n",
    "* There are 50 cases when the class was 4 and it was correctly predicted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies = [0.92727273 0.96363636 0.96363636 0.96363636 0.96363636 0.96363636\n",
      " 0.98148148 0.94444444 1.         0.94444444]\n",
      "max accuracy = 1.0\n",
      "mean = 96.15824915824916\n",
      "std = 1.912472731957569\n"
     ]
    }
   ],
   "source": [
    "k_fold(nb_classifier, X_train, y_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVC(kernel='linear', random_state=0)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Support Vector Machine (SVM)\n",
    "from sklearn.svm import SVC\n",
    "svm_classifier = SVC(kernel = 'linear', random_state = 0)\n",
    "svm_classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 4]\n",
      " [4 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]\n",
      " [2 2]\n",
      " [4 4]\n",
      " [2 2]]\n"
     ]
    }
   ],
   "source": [
    "svc_predictions = predict(svm_classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[83  4]\n",
      " [ 2 48]]\n",
      "Accuracy score = 0.9562043795620438\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           2       0.98      0.95      0.97        87\n",
      "           4       0.92      0.96      0.94        50\n",
      "\n",
      "    accuracy                           0.96       137\n",
      "   macro avg       0.95      0.96      0.95       137\n",
      "weighted avg       0.96      0.96      0.96       137\n",
      "\n"
     ]
    }
   ],
   "source": [
    "metrics(y_test, svc_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracies = [0.94545455 0.96363636 0.96363636 1.         0.94545455 1.\n",
      " 0.98148148 0.96296296 1.         0.94444444]\n",
      "max accuracy = 1.0\n",
      "mean = 97.07070707070707\n",
      "std = 2.1943977876398093\n"
     ]
    }
   ],
   "source": [
    "k_fold(svm_classifier, X_train, y_train, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q4\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choose the best performing model based on the results from performing the k-fold cross-validation. Discuss your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cross-validation results:\n",
    "\n",
    "#### Logistic Regression:\n",
    "accuracies = [0.94545455 0.96363636 0.96363636 1.         0.94545455 1.  0.96296296 0.96296296 0.98148148 0.94444444] \n",
    "\n",
    "max accuracy = 1.0 \n",
    "\n",
    "mean = 96.70033670033669 \n",
    "\n",
    "std = 1.9697976894447813\n",
    "\n",
    "#### Decision tree classifier:\n",
    "accuracies = [0.96363636 0.92727273 0.96363636 0.94545455 0.96363636 0.92727273  0.90740741 0.96296296 1.         0.96296296] \n",
    "\n",
    "max accuracy = 1.0 \n",
    "\n",
    "mean = 95.24242424242425 \n",
    "\n",
    "std = 2.4905835653388118\n",
    "\n",
    "#### Random Forest Classifier (with nb_trees = 10):\n",
    "accuracies = [0.94545455 0.96363636 0.94545455 1.         0.94545455 1.  0.94444444 0.96296296 1.         0.94444444] \n",
    "\n",
    "max accuracy = 1.0 \n",
    "\n",
    "mean = 96.51851851851852 \n",
    "\n",
    "std = 2.381554575703594\n",
    "\n",
    "#### K-Nearest Neighbors (K-NN):\n",
    "accuracies = [0.94545455 0.94545455 0.98181818 0.98181818 0.96363636 1.  0.96296296 0.96296296 0.98148148 0.94444444]\n",
    "\n",
    "max accuracy = 1.0 \n",
    "\n",
    "mean = 96.70033670033669 \n",
    "\n",
    "std = 1.7941421104663395\n",
    "\n",
    "#### Naïve Bayes:\n",
    "accuracies = [0.92727273 0.96363636 0.96363636 0.96363636 0.96363636 0.96363636  0.98148148 0.94444444 1.         0.94444444] \n",
    "\n",
    "max accuracy = 1.0 \n",
    "\n",
    "mean = 96.15824915824916 \n",
    "\n",
    "std = 1.912472731957569\n",
    "\n",
    "#### Support Vector Machine (SVM):\n",
    "accuracies = [0.94545455 0.96363636 0.96363636 1.         0.94545455 1.  0.98148148 0.96296296 1.         0.94444444] \n",
    "\n",
    "max accuracy = 1.0 \n",
    "\n",
    "mean = 97.07070707070707 \n",
    "\n",
    "std = 2.1943977876398093"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To choose the best model I will take into account the mean accuracy and the standard deviation. The bigest mean accuracy is given by the SVM, but it has a bigger standard deviation than the other models. To choose the model, I will look for the gratest `mean accuracy - std`, because this would be the model that would have a bigger accuracy with lover standard deviation. If the mean accuracy is big andthe standarts devieation  of the accurancies is small, then the model is good.\n",
    "\n",
    "* Logistic regression: mean accuracy - std = 94.72\n",
    "* Decision tree classifier: mean accuracy - std = 92.7518406771\n",
    "* Random Forest Classifier: mean accuracy - std = 94.1369639428\n",
    "* K-Nearest Neighbors (K-NN): mean accuracy - std = 94.9061945899\n",
    "* Naïve Bayes: mean accuracy - std = 94.2457764263\n",
    "* Support Vector Machine (SVM): mean accuracy - std = 94.8763092831\n",
    "\n",
    "The best result is given by K-Nearest Neighbors (K-NN). This model gave us an accyracy of 100% just once in comparison with the other models, which is good because it is not desirable to have 100% accuracy for the model trained on the subsets.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "KNeighborsClassifier hyperparameters chosen to tweak:\n",
    "\n",
    "`n_neighbors` - we will tweak this one because a different number of neighbors might give us a different result, depending on how the data is distributed. This parameter represents how many neighbors will be taken in to accocunt when classifying a new data point. \n",
    "\n",
    "`p` - we will tweak this one because it may change the results. Power parameter for the Minkowski metric. When p = 1, this is equivalent to using manhattan_distance (l1), and euclidean_distance (l2) for p = 2. For arbitrary p, minkowski_distance (l_p) is used.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List Hyperparameters that we want to tune\n",
    "n_neighbors = [5, 10, 15, 20]\n",
    "p=[1,2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The only maccepted values for p are 1 and 2. I assume that p=2 (Euclidean distance) is the best choice because this distance is unique and it shows the shortest direct path. \n",
    "\n",
    "I assume that if there are more neighbors taken into account, the model will be more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accucary score = 0.9562043795620438\n",
      "Best p: 2\n",
      "Best n_neighbors: 10\n"
     ]
    }
   ],
   "source": [
    "# GridSearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "hyperparameters = dict(n_neighbors=n_neighbors, p=p)\n",
    "clf = GridSearchCV(knn_classifier, hyperparameters, cv=10)\n",
    "best_model = clf.fit(X_train, y_train)\n",
    "\n",
    "print(\"Accucary score = {}\".format(best_model.score(X_test, y_test)))\n",
    "print('Best p:', best_model.best_estimator_.get_params()['p'])\n",
    "print('Best n_neighbors:', best_model.best_estimator_.get_params()['n_neighbors'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My assumption regarding p was correct. What about n_neighbours, I concluded that not alwasys more neighbors will make the model better."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
